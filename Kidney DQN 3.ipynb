{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import kidney\n",
    "import tensorflow.contrib.layers as skflow\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'Kidney'  # Environment name\n",
    "NUM_PATIENTS = 20\n",
    "NUM_EPISODES = 100000  # Number of episodes the agent plays\n",
    "GAMMA = .99  # Discount factor\n",
    "LAMBDA = .9  # Regularization factor\n",
    "KEEP_PROB = .8  # Dropout keep prob rate\n",
    "EXPLORATION_STEPS = 1000000 # Number of steps over which the initial value of epsilon is linearly annealed to its final value\n",
    "INITIAL_EPSILON = 0.2  # Initial value of epsilon in epsilon-greedy\n",
    "FINAL_EPSILON = 0.000  # Final value of epsilon in epsilon-greedy\n",
    "INITIAL_REPLAY_SIZE = 256  # Number of steps to populate the replay memory before training starts\n",
    "NUM_REPLAY_MEMORY = 2000  # Number of replay memory the agent uses for training\n",
    "BATCH_SIZE = 32  # Mini batch size\n",
    "TARGET_UPDATE_INTERVAL = 250  # The frequency with which the target network is updated\n",
    "TEST_EVERY = 100\n",
    "TRAIN_INTERVAL = 4  # The agent selects 4 actions between successive updates\n",
    "LEARNING_RATE = 0.025  # Learning rate used by RMSProp\n",
    "MOMENTUM = 0.95  # Momentum used by RMSProp\n",
    "MIN_GRAD = 0.01  # Constant added to the squared gradient in the denominator of the RMSProp update\n",
    "NO_OP_STEPS = 0  # Maximum number of \"do nothing\" actions to be performed by the agent at the start of an episode\n",
    "LOAD_NETWORK = False\n",
    "TRAIN = True\n",
    "SAVE_NETWORK_PATH = 'saved_networks/' + ENV_NAME\n",
    "SAVE_SUMMARY_PATH = 'summary/' + ENV_NAME\n",
    "NUM_EPISODES_AT_TEST = 1  # Number of episodes the agent plays at test time\n",
    "PRINT_EVERY = 100\n",
    "PLOT_EVERY = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = kidney.KidneyExchange(init_size = NUM_PATIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_actions = 45\n",
    "state_dim = 16\n",
    "discount_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_dim, num_actions):\n",
    "        self.state_dim = state_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.epsilon = INITIAL_EPSILON\n",
    "        self.epsilon_step = (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORATION_STEPS\n",
    "        self.t = 0\n",
    "\n",
    "        # Parameters used for summary\n",
    "        self.total_reward = 0\n",
    "        self.total_q_max = 0\n",
    "        self.total_loss = 0\n",
    "        self.duration = 0\n",
    "        self.episode = 0\n",
    "        \n",
    "        self.training_loss = []\n",
    "\n",
    "        # Create replay memory\n",
    "        self.replay_memory = deque(maxlen = NUM_REPLAY_MEMORY)\n",
    "\n",
    "        # Create q network\n",
    "        with tf.variable_scope(\"q_network\"):\n",
    "            self.s, self.q_values = self.build_network()\n",
    "        self.q_network_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"q_network\")\n",
    "        \n",
    "        # Create target network\n",
    "        with tf.variable_scope(\"target_network\"):\n",
    "            self.st, self.target_q_values = self.build_network()\n",
    "        self.target_network_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"target_network\")\n",
    "        \n",
    "        \n",
    "        self.a, self.y, self.loss, self.grad_update = self.build_training_op(self.q_network_weights)\n",
    "        \n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "   \n",
    "    def build_network(self):\n",
    "        s = tf.placeholder(tf.float32, (None, self.state_dim), name=\"states\")\n",
    "        net = skflow.fully_connected(s, 5,\n",
    "                                    weights_initializer = skflow.xavier_initializer(uniform = False),\n",
    "                                    weights_regularizer = skflow.l2_regularizer(LAMBDA))\n",
    "        net = skflow.dropout(net, KEEP_PROB)\n",
    "        net = skflow.fully_connected(net, 5,\n",
    "                                    weights_initializer = skflow.xavier_initializer(uniform = False),\n",
    "                                    weights_regularizer = skflow.l2_regularizer(LAMBDA))\n",
    "        net = skflow.dropout(net, KEEP_PROB)\n",
    "        q_values = skflow.fully_connected(net, self.num_actions,\n",
    "                                    weights_initializer = skflow.xavier_initializer(uniform = False),\n",
    "                                    weights_regularizer = skflow.l2_regularizer(LAMBDA))\n",
    "        return s, q_values\n",
    "    \n",
    "    def get_action(self, state, avail, train = True):\n",
    "        if train and np.random.uniform() <= self.epsilon:\n",
    "            avail_actions = np.arange(self.num_actions)[avail.flatten()]\n",
    "            #import pdb; pdb.set_trace()\n",
    "            action = np.random.choice(avail_actions)\n",
    "        else:\n",
    "            qvals = self.q_values.eval(feed_dict={self.s: state})\n",
    "            qvals[~avail] = -np.inf \n",
    "            action = np.argmax(qvals)\n",
    "            \n",
    "        if train:\n",
    "            # Anneal epsilon linearly over time\n",
    "            if self.epsilon > FINAL_EPSILON and self.t >= INITIAL_REPLAY_SIZE:\n",
    "                self.epsilon -= self.epsilon_step\n",
    "        return action\n",
    "\n",
    "    \n",
    "    def run(self, state, action, reward, next_state, terminal):\n",
    "        \n",
    "        # Store transition in replay memory\n",
    "        self.replay_memory.append((state, action, reward, next_state, terminal))\n",
    "       \n",
    "        if self.t >= INITIAL_REPLAY_SIZE:\n",
    "            # Train network\n",
    "            if self.t % TRAIN_INTERVAL == 0:\n",
    "                loss = self.train_network()\n",
    "                self.training_loss.append(loss)\n",
    "                \n",
    "            # Update target network\n",
    "            if self.t % TARGET_UPDATE_INTERVAL == 0:\n",
    "                self.update_target_network()\n",
    "            \n",
    "        self.t += 1\n",
    "        \n",
    "\n",
    "    def update_target_network(self):\n",
    "        for v_q, v_target in zip(self.q_network_weights, self.target_network_weights):\n",
    "            v_target.assign(v_q)\n",
    "    \n",
    "    \n",
    "    def train_network(self):\n",
    "        state_batch = []\n",
    "        action_batch = []\n",
    "        reward_batch = []\n",
    "        next_state_batch = []\n",
    "        terminal_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        # Sample random minibatch of transition from replay memory\n",
    "        minibatch = random.sample(self.replay_memory, BATCH_SIZE)\n",
    "        for data in minibatch:\n",
    "            state_batch.append(data[0])\n",
    "            action_batch.append(data[1])\n",
    "            reward_batch.append(data[2])\n",
    "            next_state_batch.append(data[3])\n",
    "            terminal_batch.append(data[4])\n",
    "\n",
    "        # Convert to appropriate types\n",
    "        state_batch = np.vstack(state_batch).astype(np.float32)\n",
    "        reward_batch = np.vstack(reward_batch).astype(np.float32)\n",
    "        action_batch = np.vstack(action_batch).astype(np.float32)\n",
    "        next_state_batch = np.vstack(next_state_batch).astype(np.float32)\n",
    "        terminal_batch = np.vstack(terminal_batch).astype(np.int32)\n",
    "        \n",
    "        # Find max_a Qhat(s[t+1],a)\n",
    "        target_q_values_batch = self.target_q_values.eval(feed_dict={self.st: next_state_batch})\n",
    "        y_batch = reward_batch + (1 - terminal_batch) * GAMMA * np.max(target_q_values_batch, axis=1).reshape(-1, 1)\n",
    "\n",
    "        # Compute loss and update\n",
    "        loss, _ = self.sess.run([self.loss, self.grad_update], feed_dict={\n",
    "            self.s: state_batch,\n",
    "            self.a: action_batch,\n",
    "            self.y: y_batch\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "        \n",
    "    def build_training_op(self, q_network_weights):\n",
    "        a = tf.placeholder(tf.int64, [None,1], name = \"a\")\n",
    "        y = tf.placeholder(tf.float32, [None,1], name = \"y\")\n",
    "\n",
    "        # Convert action to one hot vector\n",
    "        a_one_hot = tf.one_hot(a, self.num_actions, 1.0, 0.0)\n",
    "        q_value = tf.reduce_sum(tf.mul(self.q_values, a_one_hot), reduction_indices=1)\n",
    "\n",
    "        # Clip the error, the loss is quadratic when the error is in (-1, 1), and linear outside of that region\n",
    "        error = tf.abs(y - q_value)\n",
    "        quadratic_part = tf.clip_by_value(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = tf.reduce_mean(0.5 * tf.square(quadratic_part) + linear_part)\n",
    "\n",
    "        #optimizer = tf.train.RMSPropOptimizer(LEARNING_RATE, momentum=MOMENTUM, epsilon=MIN_GRAD)\n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "        grad_update = optimizer.minimize(loss, var_list=q_network_weights)\n",
    "\n",
    "        return a, y, loss, grad_update\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = kidney.KidneyExchange(init_size = NUM_PATIENTS)\n",
    "agent = Agent(num_actions = 45, state_dim = 16)\n",
    "losses = deque(maxlen = 100)\n",
    "match_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_state = env.reset(True).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.694767 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "100 0.694757 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "200 0.69474 -3.691236499641057e-12\n",
      "Matched 8 out of 8 possible\n",
      "300 0.694725 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "400 0.694715 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "500 0.694704 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "600 0.6947 -3.691236499641057e-12\n",
      "Matched 12 out of 14 possible\n",
      "700 0.694686 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "800 0.694672 -3.691236499641057e-12\n",
      "Matched 20 out of 24 possible\n",
      "900 0.694668 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "1000 0.69466 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "1100 0.69465 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "1200 0.694632 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "1300 0.694617 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "1400 0.694604 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "1500 0.694597 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "1600 0.694594 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "1700 0.694579 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "1800 0.694569 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "1900 0.69456 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "2000 0.694555 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "2100 0.694538 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "2200 0.694521 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "2300 0.694506 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "2400 0.694502 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "2500 0.694498 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "2600 0.69449 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "2700 0.694483 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "2800 0.694475 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "2900 0.694466 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "3000 0.694459 -3.691236499641057e-12\n",
      "Matched 14 out of 20 possible\n",
      "3100 0.694448 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "3200 0.694434 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "3300 0.694416 -3.691236499641057e-12\n",
      "Matched 10 out of 10 possible\n",
      "3400 0.694399 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "3500 0.694389 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "3600 0.694376 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "3700 0.694366 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "3800 0.694358 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "3900 0.694353 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "4000 0.694343 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "4100 0.694332 -3.691236499641057e-12\n",
      "Matched 20 out of 22 possible\n",
      "4200 0.694328 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "4300 0.694325 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "4400 0.694319 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "4500 0.694312 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "4600 0.694305 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "4700 0.694298 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "4800 0.694286 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "4900 0.694277 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "5000 0.694274 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "5100 0.694264 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "5200 0.694248 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "5300 0.694235 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "5400 0.694225 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "5500 0.694207 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "5600 0.694202 -3.691236499641057e-12\n",
      "Matched 18 out of 22 possible\n",
      "5700 0.694198 -3.691236499641057e-12\n",
      "Matched 12 out of 16 possible\n",
      "5800 0.694195 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "5900 0.694183 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "6000 0.694167 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "6100 0.694144 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "6200 0.694125 -3.691236499641057e-12\n",
      "Matched 10 out of 10 possible\n",
      "6300 0.694111 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "6400 0.694107 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "6500 0.694107 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "6600 0.694098 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "6700 0.694084 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "6800 0.694077 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "6900 0.69406 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "7000 0.694042 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "7100 0.694021 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "7200 0.694001 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "7300 0.693982 -3.691236499641057e-12\n",
      "Matched 10 out of 12 possible\n",
      "7400 0.693966 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "7500 0.69395 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "7600 0.693932 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "7700 0.693922 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "7800 0.693911 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "7900 0.693902 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "8000 0.693896 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "8100 0.693885 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "8200 0.693873 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "8300 0.693858 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "8400 0.693843 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "8500 0.693825 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "8600 0.693805 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "8700 0.693787 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "8800 0.693775 -3.691236499641057e-12\n",
      "Matched 10 out of 10 possible\n",
      "8900 0.693761 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "9000 0.693751 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "9100 0.693745 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "9200 0.693744 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "9300 0.693738 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "9400 0.693738 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "9500 0.693737 -3.691236499641057e-12\n",
      "Matched 12 out of 14 possible\n",
      "9600 0.693737 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "9700 0.693737 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "9800 0.693731 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "9900 0.693724 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "10000 0.693709 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "10100 0.693697 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "10200 0.693684 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "10300 0.693671 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "10400 0.693661 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "10500 0.693652 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "10600 0.693636 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "10700 0.693614 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "10800 0.693597 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "10900 0.693585 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "11000 0.69358 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "11100 0.693572 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "11200 0.693561 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "11300 0.693539 -3.691236499641057e-12\n",
      "Matched 14 out of 20 possible\n",
      "11400 0.693516 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "11500 0.693506 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "11600 0.6935 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "11700 0.693498 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "11800 0.693486 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "11900 0.693481 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "12000 0.693476 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "12100 0.693465 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "12200 0.693446 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "12300 0.693438 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "12400 0.693429 -3.691236499641057e-12\n",
      "Matched 14 out of 18 possible\n",
      "12500 0.693419 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "12600 0.693404 -3.691236499641057e-12\n",
      "Matched 18 out of 22 possible\n",
      "12700 0.693395 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "12800 0.693381 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "12900 0.693371 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "13000 0.69336 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "13100 0.693347 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "13200 0.693334 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "13300 0.69332 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "13400 0.693314 -3.691236499641057e-12\n",
      "Matched 18 out of 22 possible\n",
      "13500 0.693306 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "13600 0.693298 -3.691236499641057e-12\n",
      "Matched 14 out of 18 possible\n",
      "13700 0.693287 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "13800 0.69328 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "13900 0.693269 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "14000 0.693268 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "14100 0.693258 -3.691236499641057e-12\n",
      "Matched 20 out of 24 possible\n",
      "14200 0.693249 -3.691236499641057e-12\n",
      "Matched 12 out of 14 possible\n",
      "14300 0.693232 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "14400 0.69322 -3.691236499641057e-12\n",
      "Matched 20 out of 26 possible\n",
      "14500 0.693211 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "14600 0.693204 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "14700 0.693192 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "14800 0.693178 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "14900 0.693161 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "15000 0.693139 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "15100 0.693118 -3.691236499641057e-12\n",
      "Matched 16 out of 20 possible\n",
      "15200 0.693104 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "15300 0.693091 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "15400 0.693078 -3.691236499641057e-12\n",
      "Matched 14 out of 18 possible\n",
      "15500 0.693059 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "15600 0.69304 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "15700 0.693018 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "15800 0.693003 -3.691236499641057e-12\n",
      "Matched 18 out of 22 possible\n",
      "15900 0.692991 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "16000 0.692985 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "16100 0.692976 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "16200 0.692973 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "16300 0.692968 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "16400 0.692974 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "16500 0.692968 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "16600 0.692961 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "16700 0.69295 -3.691236499641057e-12\n",
      "Matched 12 out of 14 possible\n",
      "16800 0.692936 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "16900 0.692927 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "17000 0.692912 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "17100 0.692901 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "17200 0.692885 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "17300 0.692871 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "17400 0.69286 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "17500 0.692855 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "17600 0.692849 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "17700 0.692841 -3.691236499641057e-12\n",
      "Matched 18 out of 26 possible\n",
      "17800 0.69284 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "17900 0.692837 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "18000 0.692827 -3.691236499641057e-12\n",
      "Matched 20 out of 22 possible\n",
      "18100 0.692819 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "18200 0.692817 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "18300 0.69281 -3.691236499641057e-12\n",
      "Matched 12 out of 14 possible\n",
      "18400 0.692799 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "18500 0.692798 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "18600 0.692795 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "18700 0.692789 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "18800 0.692776 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "18900 0.692762 -3.691236499641057e-12\n",
      "Matched 14 out of 20 possible\n",
      "19000 0.692749 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "19100 0.692732 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "19200 0.692717 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "19300 0.692702 -3.691236499641057e-12\n",
      "Matched 16 out of 18 possible\n",
      "19400 0.6927 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "19500 0.692698 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "19600 0.69269 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "19700 0.692683 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "19800 0.692674 -3.691236499641057e-12\n",
      "Matched 12 out of 12 possible\n",
      "19900 0.692662 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "20000 0.692653 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "20100 0.692643 -3.691236499641057e-12\n",
      "Matched 20 out of 22 possible\n",
      "20200 0.692629 -3.691236499641057e-12\n",
      "Matched 20 out of 20 possible\n",
      "20300 0.692616 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "20400 0.692606 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "20500 0.69259 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n",
      "20600 0.692574 -3.691236499641057e-12\n",
      "Matched 18 out of 20 possible\n",
      "20700 0.692557 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "20800 0.69254 -3.691236499641057e-12\n",
      "Matched 14 out of 18 possible\n",
      "20900 0.692525 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "21000 0.692511 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "21100 0.692498 -3.691236499641057e-12\n",
      "Matched 14 out of 14 possible\n",
      "21200 0.692487 -3.691236499641057e-12\n",
      "Matched 14 out of 16 possible\n",
      "21300 0.692483 -3.691236499641057e-12\n",
      "Matched 18 out of 18 possible\n",
      "21400 0.692478 -3.691236499641057e-12\n",
      "Matched 16 out of 16 possible\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-48619beb41f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmatched_patients\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitorhadad/Documents/Kidney/kidney.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a, new_pairs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Recheck if game is over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mavail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mzero_avail_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mburst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitorhadad/Documents/Kidney/kidney.py\u001b[0m in \u001b[0;36mavailable_actions\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mavail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mavail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vitorhadad/anaconda/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i_episode in range(NUM_EPISODES):\n",
    "    terminal = False\n",
    "    state = env.reset(True)\n",
    "    avail = env.available_actions()\n",
    "    max_patients = env.get_max_patients()\n",
    "    if max_patients == 0: \n",
    "        i_episode -= 1\n",
    "        continue\n",
    "    matched_patients = 0\n",
    "    while not terminal:\n",
    "        action = agent.get_action(state, avail)\n",
    "        next_state, reward, terminal, avail = env.step(action, False)\n",
    "        matched_patients += 2\n",
    "        if terminal: \n",
    "            penalty = matched_patients - max_patients\n",
    "            reward += penalty \n",
    "        agent.run(state, action, reward, next_state, terminal)\n",
    "        \n",
    "    losses.append(agent.training_loss)\n",
    "    if i_episode % PRINT_EVERY == 0 and len(losses) > 20:\n",
    "        print(i_episode, np.mean(losses), agent.epsilon)\n",
    "        \n",
    "    if i_episode % PLOT_EVERY == 0:\n",
    "        fig, ax = plt.subplots(1, 2, figsize = (15, 3))\n",
    "        ax[0].plot(match_prob)\n",
    "        if len(match_prob) > 100:\n",
    "            pd.Series(match_prob).rolling(100).mean().plot(ax = ax[1])\n",
    "        fig.savefig(\"match_prob\")\n",
    "        plt.close(\"all\")\n",
    "        \n",
    "    if i_episode % TEST_EVERY == 0:\n",
    "        terminal = False\n",
    "        state = env.reset(True)\n",
    "        avail = env.available_actions()\n",
    "        max_patients = env.get_max_patients()\n",
    "        if max_patients == 0: continue\n",
    "        matched_patients = 0\n",
    "        while not terminal:\n",
    "            action = agent.get_action(state, avail)\n",
    "            next_state, reward, terminal, avail = env.step(action, False)\n",
    "            matched_patients += 2\n",
    "            if terminal: \n",
    "                penalty = matched_patients - max_patients\n",
    "                reward += penalty \n",
    "\n",
    "        print(\"Matched {} out of {} possible\".format(matched_patients, max_patients))\n",
    "        match_prob.append(matched_patients / max_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04612419999614337"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a, a)      4\n",
      "(a, b)      3\n",
      "(a, ab)     1\n",
      "(a, o)      1\n",
      "(b, a)      2\n",
      "(b, b)      4\n",
      "(b, ab)     1\n",
      "(b, o)      0\n",
      "(ab, a)     1\n",
      "(ab, b)     0\n",
      "(ab, ab)    0\n",
      "(ab, o)     0\n",
      "(o, a)      0\n",
      "(o, b)      1\n",
      "(o, ab)     2\n",
      "(o, o)      0\n",
      "dtype: int64\n",
      "self_demanded self_demanded\n",
      "self_demanded self_demanded\n",
      "recip_demanded recip_demanded\n",
      "recip_demanded recip_demanded\n",
      "recip_demanded over_demanded\n",
      "self_demanded self_demanded\n",
      "self_demanded self_demanded\n"
     ]
    }
   ],
   "source": [
    "terminal = False\n",
    "state = env.reset(True)\n",
    "print(env.state)\n",
    "avail = env.available_actions()\n",
    "max_patients = env.get_max_patients()\n",
    "matched_patients = 0\n",
    "while not terminal:\n",
    "    action = agent.get_action(state, avail)\n",
    "    p1, p2 = env.exchanges[action]\n",
    "    print(env.how_demanded(p1), env.how_demanded(p2))\n",
    "    next_state, reward, terminal, avail = env.step(action, False)\n",
    "    matched_patients += 2\n",
    "    if terminal: \n",
    "        penalty = matched_patients - max_patients\n",
    "        reward += penalty \n",
    "    agent.run(state, action, reward, next_state, terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_patients, matched_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
